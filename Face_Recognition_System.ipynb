{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition_System.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sRETmHfrKiJ"
      },
      "source": [
        "!pip install mtcnn\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications\n",
        "!pip install twilio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8ZJfXB_rnre"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import cv2\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from scipy.spatial.distance import cosine\n",
        "import urllib.request\n",
        "import requests\n",
        "import threading\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR-Xvrpttzzs"
      },
      "source": [
        "def face_det_ext(img): \n",
        "    face_det=MTCNN()\n",
        "    faces=face_det.detect_faces(img)\n",
        "    co=list(faces[0]['box'])\n",
        "    x1, y1, x2, y2=co[0], co[1], co[0]+co[2], co[1]+co[3]\n",
        "    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255),10)\n",
        "    cp=img[y1:y2,x1:x2]\n",
        "    plt.imshow(cp)\n",
        "    return cp \n",
        "\n",
        "def pre_proc(img1):\n",
        "    img1=cv2.resize(img1, (224,224))\n",
        "    img1=np.expand_dims(img1, axis=0)\n",
        "    return img1\n",
        "\n",
        "def get_model_scores(faces):\n",
        "    samples=np.array(faces, 'float32')\n",
        "    samples=preprocess_input(samples, version=2)\n",
        "    model=VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3), pooling='avg')\n",
        "    return model.predict(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFDgEZTkwyTz"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CmRsiB-55PF"
      },
      "source": [
        "from twilio.rest import Client\n",
        "    \n",
        "def register():\n",
        "  ch=\"y\";\n",
        "  while ch==\"y\":\n",
        "    filename = take_photo();\n",
        "    print('Saved to {}'.format(filename));\n",
        "    img=plt.imread('/content/photo.jpg');\n",
        "    img=face_det_ext(img);\n",
        "    img=pre_proc(img);\n",
        "    score=get_model_scores(img);\n",
        "    name=input(\"Give Name:\");\n",
        "    mobile=input(\"Enter your Mobile No:\")\n",
        "    scores.append([score,name,mobile]);\n",
        "    ch=input(\"Wanna add more faces? (y/n)\");\n",
        "\n",
        "def thingspeak_post(valm):\n",
        "    val=\"x\"+valm\n",
        "    URL='https://api.thingspeak.com/update?api_key='\n",
        "    KEY='PGT5KWK1GDGZULFX'\n",
        "    HEADER='&field1={}'.format(val)\n",
        "    NEW_URL=URL+KEY+HEADER\n",
        "    print(NEW_URL)\n",
        "    data=urllib.request.urlopen(NEW_URL)\n",
        "    print(data)\n",
        "\n",
        "def scan():\n",
        "  filename = take_photo();\n",
        "  print('Saved to {}'.format(filename));\n",
        "  img=plt.imread('/content/photo.jpg');\n",
        "  plt.imshow(img);\n",
        "  img=face_det_ext(img);\n",
        "  img=pre_proc(img);\n",
        "  sc=get_model_scores(img);\n",
        "  flag=0;\n",
        "  for score in scores:\n",
        "    if(cosine(score[0],sc)<0.4):\n",
        "      print('Hi',score[1]);\n",
        "      flag=1;\n",
        "      k=\"y\"\n",
        "      break\n",
        "  if(flag==0):\n",
        "    print(\"Wait a minute! Who are you?\")\n",
        "    k=\"n\"\n",
        "    client = Client('AC06bed9af7d55e1512571af4433174a43', '8cc534e15e7171ebce790489a57a6417')\n",
        "    client.messages.create(from_='+19044585957',\n",
        "                       to=score[2],\n",
        "                       body='Unautorized person detected outside your house!')\n",
        "    print(\"Message sent to the Authorized User\")\n",
        "\n",
        "  thingspeak_post(k)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJAiPzSnCw_u"
      },
      "source": [
        "scores=[]\n",
        "register()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47nsunmtFOVn"
      },
      "source": [
        "scan()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}